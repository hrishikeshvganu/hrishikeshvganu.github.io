<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Building a SOTA Search Ranking System</title>
<meta name="generator" content="Org mode" />
<link rel="stylesheet" href="https://cdn.simplecss.org/simple.min.css" />
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Building a SOTA Search Ranking System</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org4f64cc2">Ranking errors on the first page is worse (for the user) than  on later pages</a>
<ul>
<li><a href="#orgc38d005">Capturing this property through ML is not easy</a>
<ul>
<li><a href="#org0460d5d">How to find a proxy metric?</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org831d4fd">Real world ranking needs to be efficient: inference latency and throughput, training cost &amp; sample efficiency matter</a>
<ul>
<li><a href="#org8a7510d">Inference latency</a>
<ul>
<li><a href="#org5e9f351">Parallelize the work</a></li>
<li><a href="#orgc730126">Do less work</a></li>
<li><a href="#orgd6e24ac">System optimizations</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org4f64cc2" class="outline-2">
<h2 id="org4f64cc2">Ranking errors on the first page is worse (for the user) than  on later pages</h2>
<div class="outline-text-2" id="text-org4f64cc2">
<p>
In both cases in the figure, there are 2 products that are ranked incorrectly. The one on left is worse.
</p>

<div class="figure">
<p><img src="img/myimage.png" alt="ranking_diff" title="Action!" align="right" />
</p>
<p><span class="figure-number">Figure 1: </span>All ranking errors are not the same</p>
</div>
</div>

<div id="outline-container-orgc38d005" class="outline-3">
<h3 id="orgc38d005">Capturing this property through ML is not easy</h3>
<div class="outline-text-3" id="text-orgc38d005">
<p>
A loss like NDCG takes into account this consideration.
\[NDCG@k = \sum_{1}^{k}GAIN(i) DISCOUNT(i) \]
Note: I use x&lt;- y  to denote that x depends on y.
</p>
<ul class="org-ul">
<li>DISCOUNT depends on the rank (r).</li>
<li>DISCOUNT&lt;-Rank&lt;- Predicted score (\(S_i\))</li>
<li>\(S_{i}\)&lt;-\(\Theta\) (parameters over which the NDCG can be optimized)</li>
</ul>
<p>
However the rank of a product is a step function of the predicted score.
</p>


<p>
<b>Therefore need to find a proxy that's differentiable and is an upper bound for NDCG or similar losses that matter to business</b>
</p>
</div>

<div id="outline-container-org0460d5d" class="outline-4">
<h4 id="org0460d5d">How to find a proxy metric?</h4>
<div class="outline-text-4" id="text-org0460d5d">
<p>
It's not easy since it's an inverse problem. I'll go into the theory later but I'll be practical and discuss an algorithm called LambdaRank that has been very successful in the real world. I'll provide a hand wavy sketch of how it works (not a proof. There might not be a proof so I'll focus on the emprical)
<a href="https://www.microsoft.com/en-us/research/uploads/prod/2016/02/MSR-TR-2010-82.pdf">LambdaRank and LambdaMART paper</a>
</p>


<div class="figure">
<p><img src="./img/ranking_force.png" alt="ranking_force" title="Action!" align="right" />
</p>
<p><span class="figure-number">Figure 2: </span>Ranking "force" heuristic of LambdaRank</p>
</div>

<p>
\[ \mathrm{Force}_{k,l} = \lambda_{k,l}  \mathrm{Scalefactor}(k,l) \Delta NDCG (k,l) \]
Where $ Scalefactor(k,l)$ is a scaling factor from 0 to 1. This factor is larger if the difference in scores of \(k\) and \(l\) is large and negative. \(\Delta NDCG (k,l)\) is the change in NDCG if the product positons are swapped.
</p>
<ul class="org-ul">
<li>The "force" is used as the residual (gradient of the training loss) that has to be optimized through iterations of gradient boosting.</li>
<li>Thus a pair of products in mutually incorrect order gets a higher penalty if the difference in current scores is large and negative.</li>
</ul>
</div>
</div>
</div>
</div>

<div id="outline-container-org831d4fd" class="outline-2">
<h2 id="org831d4fd">Real world ranking needs to be efficient: inference latency and throughput, training cost &amp; sample efficiency matter</h2>
<div class="outline-text-2" id="text-org831d4fd">
</div>
<div id="outline-container-org8a7510d" class="outline-3">
<h3 id="org8a7510d">Inference latency</h3>
<div class="outline-text-3" id="text-org8a7510d">
<p>
Of the the three consideratios, in most Internet companies latency matters the most. Each 100ms in latency costs hard dollars. There are 3 ways to reduce the inference latency. Here we talk about only unit latency (latency for a single prediction) so that we don't have to worry about throughput
</p>
</div>

<div id="outline-container-org5e9f351" class="outline-4">
<h4 id="org5e9f351">Parallelize the work</h4>
</div>

<div id="outline-container-orgc730126" class="outline-4">
<h4 id="orgc730126">Do less work</h4>
<div class="outline-text-4" id="text-orgc730126">
<p>
Model cascades are one mechanism through which the average case unit latency can be brought down.
The key idea is:
</p>
<ul class="org-ul">
<li>A cascade has n stages.</li>
<li>At each stage there's a choice:
<ul class="org-ul">
<li>that the instance can exit the cascade and a prediction is generated</li>
<li>else the instance passes to the next model in the cascade</li>
</ul></li>
<li>The choice depends on the features of the instance. Assumption is that there is a mapping \(\bar{x}: \rightarrow {1,2, \ldots, n}\) of features \(\bar{x}\) to the stage at which the instance can exit the cascade</li>
</ul>

<p alt="cascade" title="Action!" align="right">
<a href="./img/cascade.png/" alt="cascade" title="Action!" align="right">./img/cascade.png/</a>
</p>
</div>
</div>

<div id="outline-container-orgd6e24ac" class="outline-4">
<h4 id="orgd6e24ac">System optimizations</h4>
</div>
</div>
</div>
</div>
</body>
</html>
