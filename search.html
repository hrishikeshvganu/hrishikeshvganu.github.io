<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Building a Large Scale Search Ranking System: key principles</title>
<meta name="generator" content="Org mode" />
<link rel="stylesheet" href="https://cdn.simplecss.org/simple.min.css" />
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Building a Large Scale Search Ranking System: key principles</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org04a5b4d">1. Problem Statement</a></li>
<li><a href="#org1469857">2. Ranking errors on the first page are worse (for the customer experience) than  on later pages</a>
<ul>
<li><a href="#orgfb01900">2.1. Capturing this property through ML is not easy</a>
<ul>
<li><a href="#org82c072f">2.1.1. How to find a proxy metric?</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org8936bdd">3. Real world ranking needs to be efficient: inference latency and throughput, training cost &amp; sample efficiency matter</a>
<ul>
<li><a href="#orgb7a7a50">3.1. Increase throughput(aka requests per minute)</a>
<ul>
<li><a href="#orge332db6">3.1.1. Parallelize the work</a></li>
</ul>
</li>
<li><a href="#org8c354f6">3.2. Inference latency</a>
<ul>
<li><a href="#org4ac1860">3.2.1. Do less work</a></li>
<li><a href="#orgbf750d4">3.2.2. System optimizations</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<p>
<span class="underline">Disclaimer</span>: This is a "<b>living</b>" document of my musings on search ranking in the real world and will be in an unfinished state by definition. Some of the arguments will be hand-wavy rather than rigorous since this is not a scientific publication. I will try to keep it updated as my understanding of the subject evolves.
 <b>Target audience</b><sup><a id="fnr.1" class="footref" href="#fn.1">1</a></sup>
</p>

<div id="outline-container-org04a5b4d" class="outline-2">
<h2 id="org04a5b4d"><span class="section-number-2">1</span> Problem Statement</h2>
<div class="outline-text-2" id="text-1">
<p>
For this article we make the following assmptions:
</p>
<ul class="org-ul">
<li>The domain is Ecommerce</li>
<li>User "types" their intent in the form of a query (q)</li>
<li>There is a huge collection of products. Typically tens of millions or even billions.</li>
<li>Only a few products are relevant to the user</li>
<li>Latency is important. Users expect to see results within ~ 100 ms</li>
<li>There are millions of concurrent users</li>
<li>The results are shown on what's typically called as the Product List Page (PLP). I denote this ranked list as \([p_{i}]\)</li>
<li>There are other systems in the architecture like SOLR for boolean token matching, an ML module for query understanding etc. Focus here is on search ranking so we will assume that they exists without explaining them in detail.</li>
</ul>
</div>
</div>

<div id="outline-container-org1469857" class="outline-2">
<h2 id="org1469857"><span class="section-number-2">2</span> Ranking errors on the first page are worse (for the customer experience) than  on later pages</h2>
<div class="outline-text-2" id="text-2">
<p>
In both cases in the figure, there are 2 products that are ranked incorrectly. Assume that the correct ranking is a swap. The one on left is worse.
</p>

<div class="figure">
<p><img src="img/myimage.png" alt="ranking_diff" title="Action!" align="right" />
</p>
<p><span class="figure-number">Figure 1: </span>All ranking errors are not the same</p>
</div>
</div>

<div id="outline-container-orgfb01900" class="outline-3">
<h3 id="orgfb01900"><span class="section-number-3">2.1</span> Capturing this property through ML is not easy</h3>
<div class="outline-text-3" id="text-2-1">
<p>
A loss like NDCG takes into account this consideration. The idea is to <b>inflate</b> the relevance in a super-linear way and the intuition behind the discount is that after a certain rank the rank doesn't matter (because most users don't navigate so far down).
\[NDCG@k = \sum_{1}^{k}GAIN(i) DISCOUNT(i) \]
Note: I use x&lt;- y  to denote that x depends on y.
</p>
<ul class="org-ul">
<li>DISCOUNT depends on the rank (r).</li>
<li>DISCOUNT&lt;-Rank&lt;- Predicted score (\(S_i\))</li>
<li>\(S_{i}\)&lt;-\(\Theta\) (parameters over which the NDCG can be optimized)</li>
</ul>

<p>
However the rank of a product is a step function of the predicted score. To understand why think of products A and B with score(A)=score(B) + \(\Delta\). Small changes to score of B [this is what happends during training] \(\delta < \Delta\)  don't matter.  The rank does not change for a while and as soon as \(\delta > \Delta\) the rank of both A and B  changes.<sup><a id="fnr.2" class="footref" href="#fn.2">2</a></sup>
</p>

<p>
<b>Therefore we need to find a proxy that's differentiable and is an upper bound for NDCG or similar losses that matter to business</b>
</p>
</div>

<div id="outline-container-org82c072f" class="outline-4">
<h4 id="org82c072f"><span class="section-number-4">2.1.1</span> How to find a proxy metric?</h4>
<div class="outline-text-4" id="text-2-1-1">
<p>
It's not easy since it's an inverse problem. I'll go into the theory later but I'll be practical and discuss an algorithm called LambdaRank that has been very successful in the real world. I'll provide a hand wavy sketch of how it works (not a proof. There might not be a proof so I'll focus on the emprical)
<a href="https://www.microsoft.com/en-us/research/uploads/prod/2016/02/MSR-TR-2010-82.pdf">LambdaRank and LambdaMART paper</a>
</p>


<div class="figure">
<p><img src="./img/ranking_force.png" alt="ranking_force" title="Action!" align="right" />
</p>
<p><span class="figure-number">Figure 2: </span>Ranking "force" heuristic of LambdaRank</p>
</div>

<p>
\[ \mathrm{Force}_{k,l} = \lambda_{k,l}  \mathrm{Scalefactor}(k,l) \Delta NDCG (k,l) \]
Where $ Scalefactor(k,l)$ is a scaling factor from 0 to 1. This factor is larger if the difference in scores of \(k\) and \(l\) is large and negative. \(\Delta NDCG (k,l)\) is the change in NDCG if the product positons are swapped.
</p>
<ul class="org-ul">
<li>The "force" is used as the residual (gradient of the training loss) that has to be optimized through iterations of gradient boosting.</li>
<li>Thus a pair of products in mutually incorrect order gets a higher penalty if the difference in current scores is large and negative.</li>
</ul>

<p>
Thus the total <b>force</b> on a product that is in an incorrect position is the sum of the forces exerted on it due to pairwise violations and change in NDCG by resolving those violations. This is supposed to track NDCG better than just reducing the # pairwise violations.
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-org8936bdd" class="outline-2">
<h2 id="org8936bdd"><span class="section-number-2">3</span> Real world ranking needs to be efficient: inference latency and throughput, training cost &amp; sample efficiency matter</h2>
<div class="outline-text-2" id="text-3">
</div>
<div id="outline-container-orgb7a7a50" class="outline-3">
<h3 id="orgb7a7a50"><span class="section-number-3">3.1</span> Increase throughput(aka requests per minute)</h3>
<div class="outline-text-3" id="text-3-1">
</div>
<div id="outline-container-orge332db6" class="outline-4">
<h4 id="orge332db6"><span class="section-number-4">3.1.1</span> Parallelize the work</h4>
<div class="outline-text-4" id="text-3-1-1">
<p>
The following strategies fall under this header. Note that these strategies can be used in combination as well and are not always mutually exclusive:
</p>
</div>
<ol class="org-ol">
<li><a id="org79ec380"></a>[Strategy #1]Scaling horizontally on cpus and GPUs<br />
<div class="outline-text-7" id="text-3-1-1-0-0-1">
<p>
This is the <b>brute force</b> strategy and it does not need much thought. Given a query \(q_i\) and a set of products \([p_{j}]\) the task of scoring each \(p_{j}\) against the query falls into the SIMD (Single Instruction, Multiple Data ) pattern
In practice its highly effective and often the simplest since it does not need much algorithmmic thinking.
GPUs have thousands of cores and can perform operations in parallel on multiple instances through batching. If the model is not very compute intensive then scaling by adding more cpu machines can also work.
</p>


<div class="figure">
<p><img src="./img/horizontal_scaling.png" alt="horizontal_scaling.png" />
</p>
</div>

<p>
<b>When using this strategy of distributing the load across multiple nodes, it's important to remember that all products that are being ranked for a given query need to be brought to the same node ultimately for ranking</b>
</p>

<p>
<img src="./img/gpu.png" alt="gpu.png" /><sup><a id="fnr.3" class="footref" href="#fn.3">3</a></sup>
</p>
</div>
</li>

<li><a id="org22221ed"></a>[Strategy #2]Using models that can work on the same instance in parallel<br />
<div class="outline-text-7" id="text-3-1-1-0-0-2">
<p>
This strategy can be used if the score can be <b>decomposed</b> into components that can be added together. Usually this property is restricted to linear models. This strategy was actually SOTA uptil about 2013 before the era of deep learning. Even in today's world where full attribution of the score into individual components at an instance level is needed this is one of the most suitable strategies. Eg: credit scoring systems where one might want to understand how much reduction in credit score was due to (say) a late credit card payment  in a specific month[which would be a feature in the model].
Eg: in the following equation, <b>Delinquent CC</b>, <b>Full time job</b> can be indicator variables (0/1) and due to decomposability each effect \(w_{x} x\)  can be separately computed.
</p>

<p>
\[\mathrm{Score}= w_{\mathrm{Delinquent CC}}\mathrm{Delinquent CC} + w_{\mathrm{Full time job}} \mathrm{Full time job} + ..\]
</p>

<p>
<b>Note:</b> in today's world most companies don't use such models for search ranking but when used the framework allows for massive parallelism.
</p>
</div>
</li>
</ol>
</div>
</div>

<div id="outline-container-org8c354f6" class="outline-3">
<h3 id="org8c354f6"><span class="section-number-3">3.2</span> Inference latency</h3>
<div class="outline-text-3" id="text-3-2">
<p>
At Internet  and ecommerce companies latency matters the most. Each 100ms in latency costs hard dollars. There are multiple ways to reduce the inference latency. Here we talk about only unit latency (latency for a single prediction) so that we don't have to worry about throughput
</p>
</div>

<div id="outline-container-org4ac1860" class="outline-4">
<h4 id="org4ac1860"><span class="section-number-4">3.2.1</span> Do less work</h4>
<div class="outline-text-4" id="text-3-2-1">
<p>
Model cascades are one mechanism through which the average case unit latency can be brought down.
The key idea is:
</p>
<ul class="org-ul">
<li>A cascade has n stages.</li>
<li>At each stage there's a choice:
<ul class="org-ul">
<li>that the instance can exit the cascade and a prediction is generated</li>
<li>else the instance passes to the next model in the cascade</li>
</ul></li>
<li>The choice depends on the features of the instance. Assumption is that there is a mapping \(\bar{x}: \rightarrow {1,2, \ldots, n}\) of features \(\bar{x}\) to the stage at which the instance can exit the cascade</li>
</ul>


<div class="figure">
<p><img src="./img/cascade.png" alt="ranking_force" title="Action!" align="right" />
</p>
<p><span class="figure-number">Figure 4: </span>Cascades reduce average unit latency</p>
</div>
</div>
</div>

<div id="outline-container-orgbf750d4" class="outline-4">
<h4 id="orgbf750d4"><span class="section-number-4">3.2.2</span> System optimizations</h4>
<div class="outline-text-4" id="text-3-2-2">
<p>
This is about optimizations that exploit the features of the computer architecture like memory layout, vectorization capability etc to design optimized systems. The idea is not to reduce the # high level computations but to execute them more faster.
</p>
</div>
</div>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1">1</a></sup> <div class="footpara"><p class="footpara">
<b>Who will benefit</b>
</p>
<ul class="org-ul">
<li>ML engineers interested in building low latency search ranking systems that work at internet scale (think tens of millions of concurrent users)</li>
<li>Applied ML scientists who are working in the domain of product search or document search-especially at large internet companies</li>
<li><p>
Product/Program managers and business leaders who want to understand the technical side of search ranking
</p>

<p>
<b>Who will not benefit</b>
If you are lookiing for mathematical  theory of LTR etc. this is not the right place for it.
</p></li>
</ul></div></div>

<div class="footdef"><sup><a id="fn.2" class="footnum" href="#fnr.2">2</a></sup> <div class="footpara"><p class="footpara">
If your remember grade 12 calculus, a differentiable function  of a single variable first has to be continuous-meaning the limits from left and right need to agree.
</p></div></div>

<div class="footdef"><sup><a id="fn.3" class="footnum" href="#fnr.3">3</a></sup> <div class="footpara"><p class="footpara">
<a href="http://15418.courses.cs.cmu.edu/spring2017/lecture/basicarch/slide_061">http://15418.courses.cs.cmu.edu/spring2017/lecture/basicarch/slide_061</a>
</p></div></div>


</div>
</div></div>
</body>
</html>
